--model_name_or_path meta-llama/Meta-Llama-3-8B
--cache_dir models/hf_models/
--adapters_path model_ckpts/medqa/lora/llama-3-8b-lora-32-mixed-25k-seed_9999/checkpoint-4689/
--merge_adapters
--task medqa
--result_path assets/medqa/results/lora/llama-3-8b-lora-32-mixed-25k-seed_9999.json
--output_path assets/medqa/outputs/lora/llama-3-8b-lora-32-mixed-25k-seed_9999.jsonl
--hf_token_path hf-llama.privkey
--temperature 0.0
--top_p 1.0
--top_k -1
--max_new_tokens 1
--logprobs 10
--max_model_len 8192