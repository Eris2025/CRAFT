--model_name_or_path mistral-community/Mistral-7B-v0.2
--cache_dir models/hf_models/
--task summarization
--few_shots_only
--task_samples_path assets/summarization/task_samples/32-mixed-100/
--output_dir model_ckpts/summarization/lora/mistral-7b-v0.2-lora-32-seed_1234/
--lora_r 64
--lora_alpha 64
--lora_dropout 0.1
--lora_bias none
--batch_size 1
--use_bf16
--weight_decay 0.05
--learning_rate 1e-4
--grad_acc_steps 2
--num_epochs 3
--logging_strategy steps
--logging_steps 1
--save_strategy epoch
--save_only_model
--optim adamw_torch
--warmup_ratio 0.1
--num_workers 8
--save_total_limit 1
--random_seed 1234
--hf_token_path hf-llama.privkey